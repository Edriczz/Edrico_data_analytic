{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 3136,
          "databundleVersionId": 26502,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "TitanicPred",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Edriczz/Edrico_data_analytic/blob/main/TitanicPred.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "YEZXFjoQ6e3a"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "titanic_path = kagglehub.competition_download('titanic')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "2c4hbHFf6e3d"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T06:30:52.07599Z",
          "iopub.execute_input": "2025-08-31T06:30:52.076355Z",
          "iopub.status.idle": "2025-08-31T06:30:52.421575Z",
          "shell.execute_reply.started": "2025-08-31T06:30:52.07632Z",
          "shell.execute_reply": "2025-08-31T06:30:52.420887Z"
        },
        "id": "fxB-N4Fm6e3e",
        "outputId": "9f4b32a4-d712-4abb-ae77-77924904cc61"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xgboost"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T06:44:32.855189Z",
          "iopub.execute_input": "2025-08-31T06:44:32.856013Z",
          "iopub.status.idle": "2025-08-31T06:44:37.532002Z",
          "shell.execute_reply.started": "2025-08-31T06:44:32.855985Z",
          "shell.execute_reply": "2025-08-31T06:44:37.530886Z"
        },
        "id": "JGA4wiEi6e3f",
        "outputId": "ec34b5df-5458-4b77-b4d6-eea2030c9155"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.0.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->xgboost) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->xgboost) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->xgboost) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->xgboost) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->xgboost) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#data loading and check missing values\n",
        "train_path=\"/kaggle/input/titanic/train.csv\"\n",
        "test_path=\"/kaggle/input/titanic/test.csv\"\n",
        "# Muat dataset Anda (pastikan file 'train.csv' ada di folder yang sama)\n",
        "df_train = pd.read_csv(train_path)\n",
        "# Cek jumlah nilai kosong di setiap kolom\n",
        "missing_values = df_train.isnull().sum()\n",
        "# Urutkan hasilnya agar yang paling banyak kosong ada di atas\n",
        "missing_values_sorted = missing_values[missing_values > 0].sort_values(ascending=False)\n",
        "# Tampilkan hasilnya\n",
        "print(\"Jumlah Nilai Kosong di Setiap Kolom:\")\n",
        "print(missing_values_sorted)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T06:30:55.060968Z",
          "iopub.execute_input": "2025-08-31T06:30:55.061375Z",
          "iopub.status.idle": "2025-08-31T06:30:55.089818Z",
          "shell.execute_reply.started": "2025-08-31T06:30:55.061351Z",
          "shell.execute_reply": "2025-08-31T06:30:55.088878Z"
        },
        "id": "E46Jmw9L6e3f",
        "outputId": "ae8c59c3-6dc1-4df3-f74e-5aded62203db"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Jumlah Nilai Kosong di Setiap Kolom:\nCabin       687\nAge         177\nEmbarked      2\ndtype: int64\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Cleaning (fill the missing values with median)\n",
        "import pandas as pd\n",
        "\n",
        "# (Salin lagi fungsi clean_data dari jawaban sebelumnya di sini)\n",
        "def clean_data(df):\n",
        "    df_cleaned = df.copy()\n",
        "    age_median = df_cleaned['Age'].median()\n",
        "    df_cleaned['Age'].fillna(age_median, inplace=True)\n",
        "    embarked_mode = df_cleaned['Embarked'].mode()[0]\n",
        "    df_cleaned['Embarked'].fillna(embarked_mode, inplace=True)\n",
        "    fare_median = df_cleaned['Fare'].median()\n",
        "    df_cleaned['Fare'].fillna(fare_median, inplace=True)\n",
        "    return df_cleaned\n",
        "\n",
        "# 1. Muat data asli\n",
        "df_train = pd.read_csv(train_path)\n",
        "\n",
        "# 2. Jalankan fungsi dan SIMPAN HASILNYA ke variabel baru\n",
        "df_yang_sudah_bersih = clean_data(df_train)\n",
        "\n",
        "# 3. Sekarang, cek variabel BARU tersebut\n",
        "print(\"Mengecek DataFrame yang sudah dibersihkan:\")\n",
        "print(df_yang_sudah_bersih.isnull().sum())\n",
        "\n",
        "# --- CONTOH PENGGUNAAN ---\n",
        "\n",
        "# Muat dataset\n",
        "df_train = pd.read_csv(train_path)\n",
        "\n",
        "# Tampilkan jumlah nilai kosong SEBELUM cleaning\n",
        "print(\"--- SEBELUM DATA CLEANING ---\")\n",
        "print(df_train.isnull().sum())\n",
        "print(\"-\" * 30)\n",
        "\n",
        "\n",
        "# Jalankan fungsi data cleaning\n",
        "df_cleaned = clean_data(df_train)\n",
        "\n",
        "\n",
        "# Tampilkan jumlah nilai kosong SETELAH cleaning\n",
        "print(\"\\n--- SETELAH DATA CLEANING ---\")\n",
        "print(\"Jumlah nilai kosong yang tersisa:\")\n",
        "print(df_cleaned.isnull().sum())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T06:31:04.099099Z",
          "iopub.execute_input": "2025-08-31T06:31:04.099392Z",
          "iopub.status.idle": "2025-08-31T06:31:04.137932Z",
          "shell.execute_reply.started": "2025-08-31T06:31:04.099367Z",
          "shell.execute_reply": "2025-08-31T06:31:04.137035Z"
        },
        "id": "4KF3gZOn6e3g",
        "outputId": "32c3b884-11ed-4424-e648-2a6f5ebf0bae"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Mengecek DataFrame yang sudah dibersihkan:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge              0\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         0\ndtype: int64\n--- SEBELUM DATA CLEANING ---\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n------------------------------\n\n--- SETELAH DATA CLEANING ---\nJumlah nilai kosong yang tersisa:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge              0\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         0\ndtype: int64\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_36/1934806269.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df_cleaned['Age'].fillna(age_median, inplace=True)\n/tmp/ipykernel_36/1934806269.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df_cleaned['Embarked'].fillna(embarked_mode, inplace=True)\n/tmp/ipykernel_36/1934806269.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df_cleaned['Fare'].fillna(fare_median, inplace=True)\n/tmp/ipykernel_36/1934806269.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df_cleaned['Age'].fillna(age_median, inplace=True)\n/tmp/ipykernel_36/1934806269.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df_cleaned['Embarked'].fillna(embarked_mode, inplace=True)\n/tmp/ipykernel_36/1934806269.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df_cleaned['Fare'].fillna(fare_median, inplace=True)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_engineering(df):\n",
        "    \"\"\"\n",
        "    Fungsi lengkap untuk feature engineering dataset Titanic.\n",
        "    Termasuk membuat Title, FamilySize, Deck, AgeGroup, dan konversi ke numerik.\n",
        "    \"\"\"\n",
        "    # Salin dataframe agar tidak mengubah data asli\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    # 1. Ekstrak 'Title' dari 'Name'\n",
        "    df_processed['Title'] = df_processed['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "    df_processed['Title'] = df_processed['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don',\n",
        "                                                           'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "    df_processed['Title'] = df_processed['Title'].replace({'Mlle':'Miss', 'Ms':'Miss', 'Mme':'Mrs'})\n",
        "\n",
        "    # 2. Isi 'Age' berdasarkan median 'Title' (diperlukan sebelum membuat AgeGroup)\n",
        "    age_map = df_processed.groupby('Title')['Age'].median()\n",
        "    df_processed['Age'] = df_processed['Age'].fillna(df_processed['Title'].map(age_map))\n",
        "\n",
        "    # 3. Buat 'FamilySize' dan 'IsAlone'\n",
        "    df_processed['FamilySize'] = df_processed['SibSp'] + df_processed['Parch'] + 1\n",
        "    df_processed['IsAlone'] = (df_processed['FamilySize'] == 1).astype(int)\n",
        "\n",
        "    # 4. Buat 'Deck' dari 'Cabin'\n",
        "    df_processed['Deck'] = df_processed['Cabin'].str[0].fillna('U')\n",
        "\n",
        "    # 5. Buat 'AgeGroup'\n",
        "    df_processed['AgeGroup'] = pd.cut(df_processed['Age'],\n",
        "                                      bins=[0, 12, 18, 60, 100],\n",
        "                                      labels=['Child', 'Teen', 'Adult', 'Senior'])\n",
        "\n",
        "    # 6. Isi 'Embarked' & 'Fare' yang mungkin kosong (terutama di data tes)\n",
        "    df_processed['Embarked'].fillna(df_processed['Embarked'].mode()[0], inplace=True)\n",
        "    df_processed['Fare'].fillna(df_processed['Fare'].median(), inplace=True)\n",
        "\n",
        "    # 7. Konversi semua fitur kategorikal ke numerik\n",
        "    df_processed['Sex'] = df_processed['Sex'].map({'female': 1, 'male': 0}).astype(int)\n",
        "\n",
        "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
        "    df_processed['Title'] = df_processed['Title'].map(title_mapping).fillna(0)\n",
        "\n",
        "    # Menggunakan get_dummies untuk sisanya\n",
        "    df_processed = pd.get_dummies(df_processed, columns=['Embarked', 'AgeGroup', 'Deck'], prefix=['Emb', 'Age', 'Deck'])\n",
        "\n",
        "    # 8. Hapus kolom yang tidak lagi diperlukan\n",
        "    drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp', 'Parch']\n",
        "    df_processed = df_processed.drop(drop_elements, axis=1)\n",
        "\n",
        "    return df_processed\n",
        "\n",
        "# --- CONTOH PENGGUNAAN ---\n",
        "\n",
        "# Muat data\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "# Terapkan fungsi ke data latih\n",
        "processed_train = feature_engineering(train_df)\n",
        "\n",
        "# Terapkan fungsi ke data uji\n",
        "processed_test = feature_engineering(test_df)\n",
        "\n",
        "# Pastikan kolom data uji sama dengan data latih\n",
        "train_labels = processed_train['Survived'] # Simpan label\n",
        "processed_train = processed_train.drop('Survived', axis=1)\n",
        "\n",
        "# Samakan kolom\n",
        "train_cols = processed_train.columns\n",
        "test_cols = processed_test.columns\n",
        "missing_in_test = set(train_cols) - set(test_cols)\n",
        "for c in missing_in_test:\n",
        "    processed_test[c] = 0\n",
        "processed_test = processed_test[train_cols]\n",
        "\n",
        "# Tampilkan hasil akhir\n",
        "print(\"Data Latih Setelah Feature Engineering:\")\n",
        "print(processed_train.head())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T06:31:07.957521Z",
          "iopub.execute_input": "2025-08-31T06:31:07.957859Z",
          "iopub.status.idle": "2025-08-31T06:31:08.033811Z",
          "shell.execute_reply.started": "2025-08-31T06:31:07.957834Z",
          "shell.execute_reply": "2025-08-31T06:31:08.032958Z"
        },
        "id": "KmNXWEI66e3g",
        "outputId": "413d1870-4b00-4375-b9ee-b75165eb027b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Data Latih Setelah Feature Engineering:\n   Pclass  Sex   Age     Fare  Title  FamilySize  IsAlone  Emb_C  Emb_Q  \\\n0       3    0  22.0   7.2500      1           2        0  False  False   \n1       1    1  38.0  71.2833      3           2        0   True  False   \n2       3    1  26.0   7.9250      2           1        1  False  False   \n3       1    1  35.0  53.1000      3           2        0  False  False   \n4       3    0  35.0   8.0500      1           1        1  False  False   \n\n   Emb_S  ...  Age_Senior  Deck_A  Deck_B  Deck_C  Deck_D  Deck_E  Deck_F  \\\n0   True  ...       False   False   False   False   False   False   False   \n1  False  ...       False   False   False    True   False   False   False   \n2   True  ...       False   False   False   False   False   False   False   \n3   True  ...       False   False   False    True   False   False   False   \n4   True  ...       False   False   False   False   False   False   False   \n\n   Deck_G  Deck_T  Deck_U  \n0   False   False    True  \n1   False   False   False  \n2   False   False    True  \n3   False   False   False  \n4   False   False    True  \n\n[5 rows x 23 columns]\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_36/1142771883.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df_processed['Embarked'].fillna(df_processed['Embarked'].mode()[0], inplace=True)\n/tmp/ipykernel_36/1142771883.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df_processed['Fare'].fillna(df_processed['Fare'].median(), inplace=True)\n/tmp/ipykernel_36/1142771883.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df_processed['Embarked'].fillna(df_processed['Embarked'].mode()[0], inplace=True)\n/tmp/ipykernel_36/1142771883.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df_processed['Fare'].fillna(df_processed['Fare'].median(), inplace=True)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T06:27:39.707993Z",
          "iopub.execute_input": "2025-08-31T06:27:39.70867Z",
          "iopub.status.idle": "2025-08-31T06:27:39.722133Z",
          "shell.execute_reply.started": "2025-08-31T06:27:39.708638Z",
          "shell.execute_reply": "2025-08-31T06:27:39.721089Z"
        },
        "id": "NM-vmpwC6e3h",
        "outputId": "553329b2-afc7-4b7b-bba6-b2c4925091db"
      },
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Asumsikan Anda sudah memiliki DataFrame 'processed_train' dan 'processed_test'\n",
        "# dari langkah feature engineering sebelumnya.\n",
        "\n",
        "# Pisahkan fitur (X) dan target (y) dari data latih\n",
        "X_train = processed_train\n",
        "y_train = train_labels\n",
        "\n",
        "# Data uji kita hanya berisi fitur, kita sebut saja X_test\n",
        "X_test = processed_test.copy()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T06:34:55.788872Z",
          "iopub.execute_input": "2025-08-31T06:34:55.78918Z",
          "iopub.status.idle": "2025-08-31T06:34:55.794951Z",
          "shell.execute_reply.started": "2025-08-31T06:34:55.789158Z",
          "shell.execute_reply": "2025-08-31T06:34:55.793965Z"
        },
        "id": "Oqc4uhGE6e3h"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Using random forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 1. Inisialisasi model\n",
        "# n_estimators=100 artinya kita akan membangun 100 pohon keputusan.\n",
        "# random_state=42 agar hasilnya konsisten setiap kali dijalankan.\n",
        "model = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=42)\n",
        "\n",
        "# 2. Latih model dengan data Anda\n",
        "# .fit() adalah perintah untuk \"belajar dari data\"\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model Random Forest berhasil dilatih!\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T06:38:10.437797Z",
          "iopub.execute_input": "2025-08-31T06:38:10.43812Z",
          "iopub.status.idle": "2025-08-31T06:38:12.19667Z",
          "shell.execute_reply.started": "2025-08-31T06:38:10.438095Z",
          "shell.execute_reply": "2025-08-31T06:38:12.196026Z"
        },
        "id": "25l-Cmmt6e3i",
        "outputId": "d3faab56-32a4-4dce-c990-6edd15c48dd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Model Random Forest berhasil dilatih!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Asumsikan Anda sudah memiliki X_train dan y_train dari langkah sebelumnya\n",
        "\n",
        "# 1. Bagi data untuk training dan validasi (ini penting untuk early stopping)\n",
        "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# 2. Inisialisasi model XGBoost Classifier\n",
        "model_xgb = xgb.XGBClassifier(\n",
        "    n_estimators=1000,          # Jumlah pohon yang akan dibuat (bisa banyak)\n",
        "    learning_rate=0.05,         # Seberapa cepat model belajar (nilai kecil lebih baik)\n",
        "    early_stopping_rounds=10,   # Berhenti jika performa di data validasi tidak membaik setelah 10 ronde\n",
        "    use_label_encoder=False,    # Opsi teknis untuk menghindari warning\n",
        "    eval_metric='logloss'       # Metrik untuk evaluasi saat training\n",
        ")\n",
        "\n",
        "# 3. Latih model\n",
        "# Kita memasukkan data validasi (X_val, y_val) ke dalam eval_set\n",
        "# agar model bisa memonitor performanya dan berhenti pada saat yang tepat.\n",
        "model_xgb.fit(\n",
        "    X_train_split,\n",
        "    y_train_split,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    verbose=False  # Set ke True jika ingin melihat proses training per ronde\n",
        ")\n",
        "\n",
        "# 4. Lakukan prediksi pada data validasi\n",
        "val_predictions_xgb = model_xgb.predict(X_val)\n",
        "\n",
        "# 5. Evaluasi performa model\n",
        "accuracy_xgb = accuracy_score(y_val, val_predictions_xgb)\n",
        "print(f\"Akurasi model XGBoost: {accuracy_xgb:.4f}\")\n",
        "print(\"-\" * 30)\n",
        "print(\"Classification Report XGBoost:\")\n",
        "print(classification_report(y_val, val_predictions_xgb))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T06:46:46.925608Z",
          "iopub.execute_input": "2025-08-31T06:46:46.926323Z",
          "iopub.status.idle": "2025-08-31T06:46:47.600098Z",
          "shell.execute_reply.started": "2025-08-31T06:46:46.926293Z",
          "shell.execute_reply": "2025-08-31T06:46:47.599442Z"
        },
        "id": "zqI_MrMq6e3i",
        "outputId": "6b751688-7ad0-4cac-9cfe-94b2a6ca7e66"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Akurasi model XGBoost: 0.8436\n------------------------------\nClassification Report XGBoost:\n              precision    recall  f1-score   support\n\n           0       0.83      0.91      0.87       105\n           1       0.86      0.74      0.80        74\n\n    accuracy                           0.84       179\n   macro avg       0.85      0.83      0.83       179\nweighted avg       0.84      0.84      0.84       179\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "\n",
        "# Asumsikan variabel X_train, y_train, dan X_test sudah ada dan siap digunakan.\n",
        "\n",
        "# 1. Latih ulang model dengan SELURUH data latih untuk performa maksimal.\n",
        "#    Kita menggunakan parameter yang sama atau yang sudah di-tuning.\n",
        "print(\"Melatih ulang model dengan seluruh data latih...\")\n",
        "final_model_xgb = xgb.XGBClassifier(\n",
        "    n_estimators=150,           # Jumlah pohon bisa disesuaikan berdasarkan hasil validasi\n",
        "    learning_rate=0.05,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Melatih model dengan X_train dan y_train secara penuh\n",
        "final_model_xgb.fit(X_train, y_train)\n",
        "print(\"Model final berhasil dilatih.\")\n",
        "\n",
        "\n",
        "# 2. Buat prediksi pada data uji (X_test)\n",
        "final_predictions = final_model_xgb.predict(X_test)\n",
        "\n",
        "\n",
        "# 3. Siapkan DataFrame untuk submission\n",
        "#    Kita perlu memuat 'test.csv' yang asli untuk mendapatkan kolom 'PassengerId'\n",
        "original_test_df = pd.read_csv(test_path)\n",
        "\n",
        "submission_df = pd.DataFrame({\n",
        "    'PassengerId': original_test_df['PassengerId'],\n",
        "    'Survived': final_predictions\n",
        "})\n",
        "\n",
        "\n",
        "# 4. Simpan ke file CSV\n",
        "#    Parameter index=False sangat penting agar tidak ada kolom indeks tambahan\n",
        "submission_df.to_csv('submission_xgboost.csv', index=False)\n",
        "\n",
        "print(\"\\nFile 'submission_xgboost.csv' berhasil dibuat dan siap diunggah ke Kaggle!\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T06:52:39.209873Z",
          "iopub.execute_input": "2025-08-31T06:52:39.210151Z",
          "iopub.status.idle": "2025-08-31T06:52:39.332022Z",
          "shell.execute_reply.started": "2025-08-31T06:52:39.210133Z",
          "shell.execute_reply": "2025-08-31T06:52:39.330828Z"
        },
        "id": "4nlxKthR6e3i",
        "outputId": "549a8e23-e807-408b-a822-704f15fc254b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Melatih ulang model dengan seluruh data latih...\nModel final berhasil dilatih.\n\nFile 'submission_xgboost.csv' berhasil dibuat dan siap diunggah ke Kaggle!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Bagi data latih menjadi 80% untuk training dan 20% untuk validasi\n",
        "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Latih model HANYA pada data split\n",
        "model.fit(X_train_split, y_train_split)\n",
        "\n",
        "# Lakukan prediksi pada data validasi (yang tidak dilihat model saat latihan)\n",
        "val_predictions = model.predict(X_val)\n",
        "\n",
        "# Cek akurasinya\n",
        "accuracy = accuracy_score(y_val, val_predictions)\n",
        "print(f\"Akurasi model pada data validasi: {accuracy:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T06:38:14.439832Z",
          "iopub.execute_input": "2025-08-31T06:38:14.440139Z",
          "iopub.status.idle": "2025-08-31T06:38:16.187953Z",
          "shell.execute_reply.started": "2025-08-31T06:38:14.440118Z",
          "shell.execute_reply": "2025-08-31T06:38:16.187135Z"
        },
        "id": "bwVHoRuU6e3j",
        "outputId": "bbc107cb-1eee-4b37-ed19-960381a5293e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Akurasi model pada data validasi: 0.8324\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Asumsikan X_train, y_train, dan model sudah ada dari langkah sebelumnya\n",
        "\n",
        "# Bagi data latih menjadi 80% untuk training dan 20% untuk validasi\n",
        "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Latih model HANYA pada data split\n",
        "model.fit(X_train_split, y_train_split)\n",
        "\n",
        "# Lakukan prediksi pada data validasi\n",
        "val_predictions = model.predict(X_val)\n",
        "\n",
        "# --- METRIK EVALUASI ---\n",
        "\n",
        "# 1. Cek Akurasi (seperti sebelumnya)\n",
        "accuracy = accuracy_score(y_val, val_predictions)\n",
        "print(f\"Akurasi Model: {accuracy:.4f}\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# 2. Tampilkan Confusion Matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "cm = confusion_matrix(y_val, val_predictions)\n",
        "print(cm)\n",
        "print(\"\\nPenjelasan Confusion Matrix:\")\n",
        "print(f\"True Negative (TN): {cm[0][0]}  | False Positive (FP): {cm[0][1]}\")\n",
        "print(f\"False Negative (FN): {cm[1][0]} | True Positive (TP): {cm[1][1]}\")\n",
        "print(\"\\nArtinya:\")\n",
        "print(f\"- Model dengan benar menebak {cm[0][0]} orang Tidak Selamat.\")\n",
        "print(f\"- Model dengan benar menebak {cm[1][1]} orang Selamat.\")\n",
        "print(f\"- Model salah menebak {cm[1][0]} orang sebagai Tidak Selamat (padahal Selamat).\")\n",
        "print(f\"- Model salah menebak {cm[0][1]} orang sebagai Selamat (padahal Tidak Selamat).\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "\n",
        "# 3. Tampilkan Classification Report (Precision, Recall, F1-Score)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val, val_predictions))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T06:38:22.82897Z",
          "iopub.execute_input": "2025-08-31T06:38:22.829553Z",
          "iopub.status.idle": "2025-08-31T06:38:24.585373Z",
          "shell.execute_reply.started": "2025-08-31T06:38:22.829523Z",
          "shell.execute_reply": "2025-08-31T06:38:24.584386Z"
        },
        "id": "ZyFZ0pjL6e3j",
        "outputId": "e4c1249b-c45b-40bd-ae6c-6296bed174b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Akurasi Model: 0.8324\n------------------------------\nConfusion Matrix:\n[[91 14]\n [16 58]]\n\nPenjelasan Confusion Matrix:\nTrue Negative (TN): 91  | False Positive (FP): 14\nFalse Negative (FN): 16 | True Positive (TP): 58\n\nArtinya:\n- Model dengan benar menebak 91 orang Tidak Selamat.\n- Model dengan benar menebak 58 orang Selamat.\n- Model salah menebak 16 orang sebagai Tidak Selamat (padahal Selamat).\n- Model salah menebak 14 orang sebagai Selamat (padahal Tidak Selamat).\n------------------------------\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.85      0.87      0.86       105\n           1       0.81      0.78      0.79        74\n\n    accuracy                           0.83       179\n   macro avg       0.83      0.83      0.83       179\nweighted avg       0.83      0.83      0.83       179\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Lakukan prediksi pada data uji\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# 4. Buat file submission sesuai format Kaggle\n",
        "# Kita butuh PassengerId dari file test.csv asli\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"PassengerId\": test_df[\"PassengerId\"],\n",
        "    \"Survived\": predictions\n",
        "})\n",
        "\n",
        "# Simpan ke file .csv\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"File submission.csv berhasil dibuat!\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T06:40:06.010623Z",
          "iopub.execute_input": "2025-08-31T06:40:06.011385Z",
          "iopub.status.idle": "2025-08-31T06:40:06.130684Z",
          "shell.execute_reply.started": "2025-08-31T06:40:06.011357Z",
          "shell.execute_reply": "2025-08-31T06:40:06.12977Z"
        },
        "id": "vCpglGiu6e3j",
        "outputId": "8a15ecc3-bfce-46a9-8208-9b9b93a5c2d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "File submission.csv berhasil dibuat!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}